#!/usr/bin/env python3
"""
å®Œç’§è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
éŸ³å£°ã‹ã‚‰é«˜å“è³ªnoteè¨˜äº‹ã¸ã®å®Œå…¨å¤‰æ›
"""

import os
import sys
import argparse
import tempfile
import subprocess
from pathlib import Path
import whisper
from dotenv import load_dotenv
import pyperclip
import re

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

class PerfectArticleGenerator:
    def __init__(self):
        # Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.model = None
        self.model_name = "tiny"

    def cleanup_previous_session(self):
        """å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨ã‚¯ãƒªã‚¢"""
        print(f"ğŸ”„ æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")

    def load_whisper_model(self):
        """Whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if self.model is None:
            print(f"ğŸ¤– Whisperãƒ¢ãƒ‡ãƒ« ({self.model_name}) ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            try:
                self.model = whisper.load_model(self.model_name)
                print("âœ… Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            except Exception as e:
                print(f"âŒ Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                sys.exit(1)

    def transcribe_with_whisper(self, audio_path: str) -> str:
        """Whisperã«ã‚ˆã‚‹éŸ³å£°æ–‡å­—èµ·ã“ã—"""
        try:
            self.load_whisper_model()
            result = self.model.transcribe(audio_path, language="ja")
            return result["text"]
        except Exception as e:
            print(f"âŒ Whisperæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def advanced_transcript_correction(self, transcript: str) -> str:
        """é«˜åº¦ãªæ–‡å­—èµ·ã“ã—ä¿®æ­£"""
        text = transcript.strip()
        
        # åŒ…æ‹¬çš„ãªä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³
        comprehensive_corrections = {
            # åŸºæœ¬çš„ãªåå‰ãƒ»å˜èªä¿®æ­£
            'ã¾ãªã¿': 'ãƒãƒŠãƒŸ',
            'ã¾ãªã¿ã§ã™': 'ãƒãƒŠãƒŸã§ã™',
            'ã¿ã¡ã‚ã‚“ã¾ã‚Šãªã¿ã§ã™': 'ãƒãƒŠãƒŸã§ã™',
            'ã‚µãƒ‹ãƒ¼ã®å­ã©ã‚‚': '3äººã®å­ã©ã‚‚',
            'ã•ã‚‰ã«ã®å­ã©ã‚‚': '3äººã®å­ã©ã‚‚',
            'ã¿ãªã•ã‚“ã«ã®å­ã©ã‚‚': '3äººã®å­ã©ã‚‚',
            
            # SNSãƒ»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é–¢é€£
            'SNSã¯ã—ã‚“': 'SNSç™ºä¿¡',
            'SNSç™ºä¿¡ã‚„': 'SNSç™ºä¿¡ã‚„',
            'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒšãƒ¼ã‚µã‚³': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ',
            'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã•ã“': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ',
            'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚§ã‚·ãƒ£ã‚³ãƒ¼ãƒãƒ¥ãƒ¼ã‚·ãƒ¼': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆä¸­å¿ƒ',
            'ã¾ã¾ãƒ—ãƒª': 'ãƒãƒãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹',
            'ã¾ã¾ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹': 'ãƒãƒãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹',
            'ã¾ã¾æŒ¯ã‚Šå‡ºã™': 'ãƒãƒãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹',
            
            # ãƒ©ã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£
            'Vibu Coording': 'ãƒ©ã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°',
            'ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°': 'ãƒ©ã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°',
            'Vibu': 'ãƒ©ã‚¤ãƒ–',
            'ãƒã‚¤ãƒ–': 'ãƒ©ã‚¤ãƒ–',
            'Vibu site': 'ãƒ©ã‚¤ãƒ–ã‚µã‚¤ãƒˆ',
            
            # ã‚²ãƒ¼ãƒ ãƒ»æŠ€è¡“é–¢é€£
            'ã‚ªãƒ™ãƒ³ãƒˆã‚„ã‚µãƒ³': 'ãŠå¼å½“å±‹ã•ã‚“',
            'LPæœ¬ç·¨é›†': 'LPåˆ¶ä½œ',
            'ã‚¸ãƒƒãƒˆãƒãƒ–ãƒ‡ãƒ—ãƒ­ã‚¤': 'GitHubãƒ‡ãƒ—ãƒ­ã‚¤',
            'ãƒ©ã‚¤ã‚¹ãƒãƒ›': 'ã‚¹ãƒãƒ›',
            'ã‚¢ã‚¤ãƒ‘ãƒ¼ãƒˆ': 'iPad',
            'ãƒã‚¸ã‚¢': 'ã‚²ãƒ¼ãƒ ',
            'ãƒã‚±ãƒ¢ã›ãªã„': 'ãƒã‚±ãƒ¢ãƒ³',
            'ãƒã‚±ãƒ¢ã®ã‚¢ã‚«ã‚¢': 'ãƒã‚±ãƒ¢ãƒ³ã®èµ¤',
            'ã‚²ãƒ¼ãƒ ãƒœã‚¤ãƒˆ': 'ã‚²ãƒ¼ãƒ ãƒœãƒ¼ã‚¤',
            'ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼': 'ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼',
            
            # å®—æ•™ãƒ»è–æ›¸é–¢é€£
            'æ—§å­¦ç”Ÿè€…': 'æ—§ç´„è–æ›¸',
            'ã‚½ãƒƒã‚»ãƒ¼ã‚·ãƒ§ãƒ³': 'è–æ›¸',
            'ã‚»ãƒ¼ã‚·ãƒ§ãƒ³': 'è–æ›¸',
            'ã‚¯ãƒªã‚¹ã‚¿ãƒ¼ãƒ³': 'ã‚¯ãƒªã‚¹ãƒãƒ£ãƒ³',
            'ã‚¯ãƒªã‚¹ã¡ã‚ƒã‚“': 'ã‚¯ãƒªã‚¹ãƒãƒ£ãƒ³',
            'ã‚‚ã†è¨­': 'ãƒ¢ãƒ¼ã‚»',
            'ã‚‚ã†è¨­ã£ã¦ã„ã‚‹äººç‰©': 'ãƒ¢ãƒ¼ã‚»ã¨ã„ã†äººç‰©',
            'ã‚¤ã‚¨ã‚¹ã‚­ãƒªã‚¹ãƒˆ': 'ã‚¤ã‚¨ã‚¹ãƒ»ã‚­ãƒªã‚¹ãƒˆ',
            'ãƒãƒ™ãƒ­ãƒ³æ³•é›†': 'ãƒãƒ“ãƒ­ãƒ³æ•å›š',
            'ãƒ‘ãƒ³ã‚’ãƒ•ãƒ©ã‚¹': 'ãƒ‘ãƒ³ã‚’é™ã‚‰ã›',
            'ãƒ‘ãƒ³ã‚’ãƒ•ãƒ©ã‚»': 'ãƒ‘ãƒ³ã‚’é™ã‚‰ã›',
            'ç¥ã•ã‚“ã®': 'ç¥æ§˜',
            'çœŸãª': 'ãƒãƒŠ',
            'ãƒãƒŠãƒ¼': 'ãƒãƒŠ',
            'ãƒãƒŠã‚­ãƒ£ãƒƒãƒã‚²ãƒ¼ãƒ ': 'ãƒãƒŠã‚­ãƒ£ãƒƒãƒã‚²ãƒ¼ãƒ ',
            'ã‚¦ã‚§ãƒãƒ¼ã‚¹': 'ã‚¦ã‚¨ãƒãƒ¼ã‚¹',
            'ã†ãšã‚‰': 'ã†ãšã‚‰',
            'ã‚«ãƒŸã•ã‚“': 'ç¥æ§˜',
            'ã‚‚ã†ãã®': 'ãã®',
            'ãƒ¢ãƒ¼ã‚»ã®ã‚‚ã®ãŒãŸã‚Š': 'ãƒ¢ãƒ¼ã‚»ã®ç‰©èª',
            '9æ¶æˆé•·': 'æ—§ç´„è–æ›¸',
            
            # UIãƒ»æ“ä½œé–¢é€£
            'ã‚„ã˜ã‚‹ã—': 'çŸ¢å°',
            'ã‚«ãƒ¼ã™ã‚‹': 'ã‚«ãƒ¼ã‚½ãƒ«',
            'ã“ã¤ãšãƒ¼': 'ãšãƒ¼ã£ã¨',
            'ã‚¹ãƒãƒ›ãƒƒãƒˆ': 'ã‚¹ãƒãƒ›',
            'ã‚¨ãƒ¢ã‚¸ã‚¬': 'çµµæ–‡å­—ãŒ',
            'ãƒãƒ«ãƒ¼': 'ä¸¸',
            'ã‚µãƒƒãƒ—ã‚²': 'ã‚·ãƒ³ãƒ—ãƒ«ã‚²ãƒ¼ãƒ ',
            'ã‚µãƒãƒƒã‚¯': 'ã‚µãƒã‚¯',
            'ãƒãƒ¥ãƒ¼ãƒ‰ãƒª': 'ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«',
            
            # éŸ³æ¥½ãƒ»éŸ³éŸ¿é–¢é€£
            'BGM': 'BGM',
            'ã§ã§ã§ã§ã§ã§ã§ã§ã§ã§': 'ãƒ”ãƒ­ãƒ”ãƒ­ãƒ”ãƒ­',
            'é›»å­éŸ³': 'é›»å­éŸ³',
            'ãƒ”ãƒ­ãƒ”ãƒ­': 'ãƒ”ãƒ­ãƒ”ãƒ­',
            
            # å®¶æ—ãƒ»äººé–“é–¢ä¿‚
            'ãŠã£ã¨': 'å¤«',
            'ãƒãƒ': 'æ¯',
            'ã‚¤ãƒ¢ãƒ¼ãƒˆ': 'å¦¹',
            'ãŠå­ä¾›': 'ãŠå­ã•ã‚“',
            'ãƒ¨ãƒ¼ãƒã‚§ãƒ³': 'å¹¼ç¨šåœ’',
            'å¢ƒç•Œ': 'æ•™ä¼š',
            'ãƒœã‚¯ã‚·ã‚¹': 'ç‰§å¸«',
            'ã‚¨ãƒ¼ã‚»ãƒ¼': 'å…ˆç”Ÿ',
            
            # ä¸€èˆ¬çš„ãªä¿®æ­£
            'ã†ã‚“': '',
            'ã§ãƒ¼': 'ã§',
            'ã ã‚‰ãªã‚“': 'ã ã‹ã‚‰',
            'ã†ãª': 'ã‚ˆã†ãª',
            'ã¡ã‚‡ã£ã¨': '',
            'ãªã‚“ã‹': '',
            'ã¨ã„ã†ã®': 'ã¨ã„ã†ã“ã¨',
            'ã¨ã„ã†ã¦': 'ã¨ã„ã£ã¦',
            'ãµã«': 'ã‚ˆã†ã«',
            'ã£ã¦ãµã«': 'ã¨',
            'ã†ã«': 'ã‚ˆã†ã«',
            'ã ã£ã¦': 'ã ã¨',
            'ã§ã¦': 'ã§',
            'ã¨ã¨': 'ã¨',
            'ã‚‰ã‚‰': 'ã‹ã‚‰',
            'ã ã‚‰': 'ã ã‹ã‚‰',
            'ã¦ã§': 'ã§',
            'ã¨ã§': 'ã§',
            'ã§ã§': 'ã§',
            'ã¨ã¨': 'ã¨',
            'ã†ã§ã§': 'ã§',
            'ãªã‚“ã¨': '',
            'ã¾ã‚': '',
            'ã§ã¯ã£ã¦ã¯': 'ã§ã¯',
            'ã„ã„ã†': 'ã„ã†',
            'ã„ã†ã†': 'ã„ã†',
            'ã¾ã—ãŸã§': 'ã¾ã—ãŸ',
            'ã§ã™ã§': 'ã§ã™',
            'ã—ã¾ã—ãŸã¦': 'ã—ã¾ã—ãŸ',
            'ã§ã™ã¦': 'ã§ã™',
            'ã§ã™ãŒéŸ³': 'ã§ã™ãŒ',
            'ã§ã™ã®ã§': 'ã§ã™',
            'ã‚“ã§ãªã‚“': 'ã®ã§',
            'ã‚“ã§ã™': 'ã§ã™',
            'ã®ã§ãªã‚“': 'ã®ã§',
            'ã£ã¦ãªã‚“': 'ã£ã¦',
            'ã§ãªã‚“': 'ã§',
            'ã¨ã„ã†ãªã‚“': 'ã¨ã„ã†',
            'ã‚“ã ãƒ¼': 'ã‚“ã ',
            'ã‚“ã˜ã‚ƒãªã„': 'ã‚“ã§ã¯ãªã„',
            'ã˜ã‚ƒãªã„': 'ã§ã¯ãªã„',
            'ã›ã£ã': 'ã™ã”ã',
            'ã‚ã£ã¡ã‚ƒ': 'ã¨ã¦ã‚‚',
            'ãã ã‚‰ã‚“': 'ãã ã‚‰ãªã„',
            'ã‚Šã¾ã—ã‚‡': 'ã‚Šã¾ã—ãŸ',
            'ã§ã—ãŸã¦': 'ã§ã—ãŸ',
            'ã£ãŸã®ã®ã§': 'ã£ãŸã®ã§',
            'ã ã£ãŸã†ã§': 'ã ã£ãŸã®ã§',
            'ã£ãŸã‚“ã§ãªã‚“': 'ã£ãŸã®ã§',
            'ãªã£ã„ã¦': 'ãªã£ã¦',
            'ã£ã½ã': 'ã£ã½ã',
            'ã—ã„ã¦': 'ã—ã¦',
            'ã©ã‚“ãªã‚²ãƒ¼ãƒ ã‚’ä½œã£ãŸã®': 'ã©ã®ã‚ˆã†ãªã‚²ãƒ¼ãƒ ã‚’ä½œã£ãŸã‹',
            'ã‚ªãƒ³ã‚»ã‚¤ã‚·ãƒ£ãƒ™ãƒ«': 'éŸ³å£°ã§è©±ã™',
            'ãƒ¦ãƒ¼ãƒ«ãƒ¦ãƒ¼ãƒ«': 'ã‚†ã‚‹ã‚†ã‚‹'
        }
        
        for old, new in comprehensive_corrections.items():
            text = text.replace(old, new)
        
        # ãƒ•ã‚£ãƒ©ãƒ¼ãƒ»ä¸è¦èªå¥ã®é™¤å»
        fillers = [
            'ãˆãƒ¼ã€?', 'ã‚ã®ã€?', 'ãˆã£ã¨ã€?', 'ã†ãƒ¼ã‚“ã€?', 'ã¾ãã€?',
            'ã¯ã„ã€?', 'ãã†ã€?', 'ã­ã€?', 'ã‚ˆã€?', 'ã‹ã€?'
        ]
        
        for filler in fillers:
            text = re.sub(filler, '', text)
        
        # é‡è¤‡è¡¨ç¾ã®æ•´ç†
        text = re.sub(r'ã€+', 'ã€', text)
        text = re.sub(r'ã€‚+', 'ã€‚', text)
        text = re.sub(r'\s+', ' ', text)
        
        # ä¸è‡ªç„¶ãªæ–‡å­—åˆ—ã®ä¿®æ­£
        problematic_patterns = [
            (r'ä½•ã ã‹ã‚“ã \?ç¬¬\d+å›ç›®', 'YouTubeãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ'),
            (r'ç¥åˆ¤æœŸ', 'ä¸ŠåŠæœŸ'),
            (r'ãƒ™ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ–', 'ãƒ™ã‚¹ãƒˆ5'),
            (r'ãƒãƒƒã‚¯ã‚¹\d+ã‚»ãƒ³', '5000å††'),
            (r'ã‚¹ãƒãƒ†y for your YouTube', 'ãƒãƒ†ãƒˆã®YouTube'),
            (r'ã‚¢ãƒ©ãƒ ãªãŒã‚‰', 'ã‚¢ãƒ©ãƒ¼ãƒ ãŒé³´ã‚‰ãªãã¦'),
            (r'éŸ³ãŒä½•èªã ã‘ã°ã„ã„', 'å¤«ãŒä½•åˆç‚Šã‘ã°ã„ã„'),
            (r'æŒã¡å‘ã', 'ã‚‚ã¡éº¦'),
            (r'ç™½å‰', 'ç™½ç±³'),
            (r'ãŸãã‚ãŒã‚Š', 'ç‚Šãä¸ŠãŒã‚Š'),
            (r'ã‚³ãƒ¡ãƒ³ãƒˆé£Ÿã¹ãªã„', 'ã”é£¯é£Ÿã¹ãªã„'),
            (r'åˆ†ã‹ã‚‰ãªã¾ã¾', 'ã‚ã‹ã‚‰ãªã„ã¾ã¾'),
            (r'ã‚¹ã‚¹ãƒ¡ãƒ«', 'é€²ã‚ã‚‹'),
            (r'ã‚¨ãƒãƒ«ã‚®ãƒ¥ãƒ¼ã®', 'ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®'),
            (r'é›†æœ«', 'é€±æœ«')
        ]
        
        for pattern, replacement in problematic_patterns:
            text = re.sub(pattern, replacement, text)
        
        return text

    def speech_to_writing_conversion(self, text: str) -> str:
        """è©±ã—è¨€è‘‰ã‚’æ›¸ãè¨€è‘‰ã«å¤‰æ›"""
        
        # è©±ã—è¨€è‘‰ç‰¹æœ‰ã®è¡¨ç¾ã‚’æ›¸ãè¨€è‘‰ã«å¤‰æ›
        conversions = {
            'ã£ã¦ã„ã†ãµã†ã«æ€ã„ã¾ã™': 'ã¨æ€ã„ã¾ã™',
            'ã£ã¦ã„ã†ãµã†ã«': 'ã‚ˆã†ã«',
            'ã£ã¦ã„ã†æ„Ÿã˜ã§': 'ã¨ã„ã†æ„Ÿã˜ã§',
            'ã£ã¦ã„ã†ã®ãŒ': 'ã¨ã„ã†ã“ã¨ãŒ',
            'ã£ã¦ã„ã†ã®ã¯': 'ã¨ã„ã†ã“ã¨ã¯',
            'ã£ã¦ã„ã†ã“ã¨ã§': 'ã¨ã„ã†ã“ã¨ã§',
            'ã¿ãŸã„ãªã®ã‚‚': 'ã‚ˆã†ãªã“ã¨ã‚‚',
            'ã¿ãŸã„ãªã®ã‚’': 'ã‚ˆã†ãªã“ã¨ã‚’',
            'ã“ã†ã„ã†ã“ã¨ã®': 'ã“ã®ã‚ˆã†ãª',
            'ãã†ã„ã†ã“ã¨ã®': 'ãã®ã‚ˆã†ãª',
            'ã©ã†ã„ã†ã“ã¨ã®': 'ã©ã®ã‚ˆã†ãª',
            'ã¿ãŸã„ãªæ„Ÿã˜': 'ã‚ˆã†ãªæ„Ÿã˜',
            'ã“ã‚“ãªæ„Ÿã˜': 'ã“ã®ã‚ˆã†ãªæ„Ÿã˜',
            'ãã‚“ãªæ„Ÿã˜': 'ãã®ã‚ˆã†ãªæ„Ÿã˜',
            'ã©ã‚“ãªæ„Ÿã˜': 'ã©ã®ã‚ˆã†ãªæ„Ÿã˜',
            'ã ã¨æ€ã†ã‚“ã§ã™': 'ã ã¨æ€ã„ã¾ã™',
            'ã ã¨æ€ã†ã‚“ã§ã™ã‘ã©': 'ã ã¨æ€ã„ã¾ã™ãŒ',
            'ã˜ã‚ƒãªã„ã§ã™ã‹': 'ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹',
            'ã˜ã‚ƒãªã„ã‹ãª': 'ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã™',
            'ã‹ãªã¨æ€ã„ã¾ã™': 'ã‹ã¨æ€ã„ã¾ã™',
            'ã‹ãªã¨æ€ã†ã‚“ã§ã™': 'ã‹ã¨æ€ã„ã¾ã™',
            'ãªã‚“ã§ã™ã‘ã©': 'ã§ã™ãŒ',
            'ãªã‚“ã§ã™ã‚ˆ': 'ã§ã™',
            'ãªã‚“ã§ã™ã­': 'ã§ã™',
            'ã§ã™ã‚ˆã­': 'ã§ã™',
            'ã§ã™ã­': 'ã§ã™'
        }
        
        for old, new in conversions.items():
            text = text.replace(old, new)
        
        return text

    def extract_meaningful_content(self, text: str) -> list:
        """æ„å‘³ã®ã‚ã‚‹å†…å®¹ã‚’æŠ½å‡º"""
        
        # æ–‡ã‚’åˆ†å‰²
        sentences = [s.strip() for s in text.split('ã€‚') if len(s.strip()) > 5]
        
        # æ„å‘³ã®ã‚ã‚‹æ–‡ã‚’é¸åˆ¥
        meaningful_sentences = []
        
        # ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªã‚¹ã‚­ãƒƒãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³
        skip_patterns = [
            r'ã¯ã„.*ã“ã‚“ã«ã¡ã¯',
            r'ã¨ã„ã†ã“ã¨ã§',
            r'ã¨ã„ã†ã‚ã‘ã§',
            r'èã„ã¦ãã ã•ã£ã¦.*ã‚ã‚ŠãŒã¨ã†',
            r'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ',
            r'ã§ã¯.*ä»Šæ—¥ã¯',
            r'ä»Šæ—¥ã¯.*ã§ã¯',
            r'æœ€è¿‘.*è©±.*éã',
            r'ã—ã‚ƒã¹ã‚Š.*ã™ã',
            r'ã‚¿ã‚¤ãƒˆãƒ«.*æ±ºã‚ã¦',
            r'^ä»Šæ—¥ã¯$',
            r'^ã§$',
            r'^ãã†$',
            r'^ã§ã™$',
            r'^ã¾ã™$',
            r'^ã¨ã„ã†$',
            r'éŸ³.*å‹•ãäºˆè¨­',
            r'ã§ã§.*ã§.*ã§',
            r'ã‚‰ã„ã‚ã„ã‚.*äºº',
            r'ã‚ã‚ã‚Œã¦.*ã—ã¾ãã¡ã‚ƒ',
            r'æ”¾é€.*èã„ã¦',
            r'ã‚¤ãƒ³ãƒ—ãƒƒã¨.*ã‚¤ãƒ³ãƒ—ãƒƒã¨',
            r'ãƒ¦ãƒ¼ãƒ«.*ãƒ¦ãƒ¼ãƒ«'
        ]
        
        for sentence in sentences:
            # ç©ºã®æ–‡ã‚„çŸ­ã™ãã‚‹æ–‡ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if not sentence or len(sentence) < 10:
                continue
            
            # ã‚¹ã‚­ãƒƒãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è©²å½“ã™ã‚‹æ–‡ã¯é™¤å¤–
            if any(re.search(pattern, sentence) for pattern in skip_patterns):
                continue
            
            # æ–‡å­—åŒ–ã‘ã‚„æ„å‘³ä¸æ˜ãªæ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if self.is_garbled_text(sentence):
                continue
            
            # æ—¢å­˜ã®æ–‡ã¨é¡ä¼¼ã—ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not any(self.similar_sentence(sentence, existing) for existing in meaningful_sentences):
                meaningful_sentences.append(sentence)
        
        return meaningful_sentences[:6]  # æœ€å¤§6æ–‡

    def is_garbled_text(self, text: str) -> bool:
        """æ–‡å­—åŒ–ã‘ã‚„æ„å‘³ä¸æ˜ãªæ–‡å­—åˆ—ã‚’åˆ¤å®š"""
        
        # æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³
        garbled_patterns = [
            r'[a-zA-Z]{20,}',  # é•·ã„è‹±å­—åˆ—
            r'ã€‚.*ã€‚.*ã€‚.*ã€‚.*ã€‚',  # å¥ç‚¹ãŒå¤šã™ãã‚‹
            r'^[ã€ã€‚]*$',  # å¥èª­ç‚¹ã®ã¿
            r'.*ã§.*ã§.*ã§.*ã§.*ã§.*ã§',  # ã€Œã§ã€ã®ç¹°ã‚Šè¿”ã—
            r'.*ã¨.*ã¨.*ã¨.*ã¨.*ã¨.*ã¨',  # ã€Œã¨ã€ã®ç¹°ã‚Šè¿”ã—
            r'.*ã†.*ã†.*ã†.*ã†.*ã†.*ã†',  # ã€Œã†ã€ã®ç¹°ã‚Šè¿”ã—
            r'.*ã£.*ã£.*ã£.*ã£.*ã£',  # ã€Œã£ã€ã®ç¹°ã‚Šè¿”ã—
            r'^[ã¦ã«ã‚’ã¯ãŒã®ã§ã‚‚ã‹ã‚‰]{5,}$',  # åŠ©è©ã®ã¿
        ]
        
        for pattern in garbled_patterns:
            if re.search(pattern, text):
                return True
        
        # æ„å‘³ã®ãªã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        meaningless_keywords = [
            'ã§ã§ã§ã§ã§ã§', 'ã†ã†ã†ã†', 'ã¦ã¦ã¦ã¦', 'ã®ã®ã®ã®',
            'ã‚‰ã‚‰ã‚‰ã‚‰', 'ã ã ã ã ', 'ã¾ã¾ã¾', 'ã›ã›ã›'
        ]
        
        for keyword in meaningless_keywords:
            if keyword in text:
                return True
        
        return False

    def similar_sentence(self, sent1: str, sent2: str) -> bool:
        """æ–‡ã®é¡ä¼¼æ€§ã‚’åˆ¤å®š"""
        # ç°¡å˜ãªé¡ä¼¼æ€§åˆ¤å®šï¼ˆå…±é€šå˜èªã®å‰²åˆï¼‰
        words1 = set(sent1.split())
        words2 = set(sent2.split())
        
        if not words1 or not words2:
            return False
        
        common = len(words1 & words2)
        total = len(words1 | words2)
        
        return common / total > 0.7

    def identify_main_topic(self, sentences: list) -> str:
        """ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯ã‚’ç‰¹å®š"""
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        family_keywords = ['å®¶äº‹', 'å­ã©ã‚‚', 'å¤«', 'å®¶æ—', 'è‚²å…', 'å®¶åº­']
        work_keywords = ['ä»•äº‹', 'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹', 'ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ', 'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³', 'åƒãæ–¹']
        lifestyle_keywords = ['è²·ã„ç‰©', 'Amazon', 'YouTube', 'ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ', 'ç”Ÿæ´»']
        learning_keywords = ['å­¦ç¿’', 'å‹‰å¼·', 'ç†è§£', 'ã‚ã‹ã‚‰ãªã„', 'é€²ã‚ã‚‹']
        
        all_text = ' '.join(sentences)
        
        family_count = sum(1 for keyword in family_keywords if keyword in all_text)
        work_count = sum(1 for keyword in work_keywords if keyword in all_text)
        lifestyle_count = sum(1 for keyword in lifestyle_keywords if keyword in all_text)
        learning_count = sum(1 for keyword in learning_keywords if keyword in all_text)
        
        if family_count >= 3:
            return "family"
        elif work_count >= 3:
            return "work"
        elif lifestyle_count >= 2:
            return "lifestyle"
        elif learning_count >= 2:
            return "learning"
        else:
            return "general"

    def create_structured_article(self, sentences: list, topic: str) -> str:
        """æ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ä½œæˆ"""
        
        if not sentences:
            return self.create_fallback_article()
        
        # å°å…¥éƒ¨ã‚’ä½œæˆ
        intro = self.create_topic_intro(topic, sentences)
        
        # ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†ã‚’ä½œæˆ
        main_sections = self.create_main_sections(sentences)
        
        # çµè«–éƒ¨ã‚’ä½œæˆ
        conclusion = self.create_topic_conclusion(topic)
        
        # è¨˜äº‹ã‚’çµ„ã¿ç«‹ã¦
        article_parts = [intro]
        
        for i, section in enumerate(main_sections):
            if i > 0:
                article_parts.append("---------------")
            article_parts.append(section)
        
        if conclusion:
            article_parts.append("---------------")
            article_parts.append(conclusion)
        
        return '\n\n'.join(article_parts)

    def create_topic_intro(self, topic: str, sentences: list) -> str:
        """ãƒˆãƒ”ãƒƒã‚¯ã«å¿œã˜ãŸå°å…¥éƒ¨ã‚’ä½œæˆ"""
        
        intro = "ãƒãƒŠãƒŸã§ã™ã€‚\n\n"
        
        if topic == "family":
            intro += "ä»Šå›ã¯å®¶æ—ã‚„å®¶äº‹ã«ã¤ã„ã¦æœ€è¿‘æ„Ÿã˜ã¦ã„ã‚‹ã“ã¨ã‚’ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "work":
            intro += "ä»Šå›ã¯ä»•äº‹ã‚„ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦è€ƒãˆãŸã“ã¨ã‚’ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "lifestyle":
            intro += "ä»Šå›ã¯æœ€è¿‘ã®ç”Ÿæ´»ã§å½¹ç«‹ã£ã¦ã„ã‚‹ã‚‚ã®ã‚„æ°—ã¥ã„ãŸã“ã¨ã‚’ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "learning":
            intro += "ä»Šå›ã¯å­¦ç¿’ã‚„ç†è§£ã«ã¤ã„ã¦è€ƒãˆãŸã“ã¨ã‚’ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚"
        else:
            intro += "ä»Šå›ã¯æœ€è¿‘è€ƒãˆã¦ã„ã‚‹ã“ã¨ã«ã¤ã„ã¦ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚"
        
        return intro

    def create_main_sections(self, sentences: list) -> list:
        """ãƒ¡ã‚¤ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        
        sections = []
        
        # æ–‡ã‚’æ„å‘³ã®ã‚ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²
        if len(sentences) <= 2:
            sections = ['. '.join(sentences) + '.']
        elif len(sentences) <= 4:
            mid = len(sentences) // 2
            sections = [
                '. '.join(sentences[:mid]) + '.',
                '. '.join(sentences[mid:]) + '.'
            ]
        else:
            # 3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²
            third = len(sentences) // 3
            sections = [
                '. '.join(sentences[:third]) + '.',
                '. '.join(sentences[third:2*third]) + '.',
                '. '.join(sentences[2*third:]) + '.'
            ]
        
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¸…æ›¸
        cleaned_sections = []
        for section in sections:
            cleaned = self.clean_section(section)
            if cleaned and len(cleaned.strip()) > 20:
                cleaned_sections.append(cleaned)
        
        return cleaned_sections

    def clean_section(self, section: str) -> str:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ–‡ç« ã‚’æ¸…æ›¸"""
        
        # é‡è¤‡ã™ã‚‹èªå°¾ã‚’çµ±ä¸€
        section = re.sub(r'(\.|ã€‚)+', 'ã€‚', section)
        section = re.sub(r'(ã€)+', 'ã€', section)
        
        # ä¸è‡ªç„¶ãªæ¥ç¶šã‚’ä¿®æ­£
        section = re.sub(r'ã€‚\s*ã¨', 'ã€‚', section)
        section = re.sub(r'ã€‚\s*ã§', 'ã€‚', section)
        section = re.sub(r'ã€‚\s*ãã†', 'ã€‚', section)
        
        # æ–‡ã®çµ‚ã‚ã‚Šã‚’æ•´ãˆã‚‹
        if not section.endswith('ã€‚'):
            section += 'ã€‚'
        
        return section.strip()

    def create_topic_conclusion(self, topic: str) -> str:
        """ãƒˆãƒ”ãƒƒã‚¯ã«å¿œã˜ãŸçµè«–éƒ¨ã‚’ä½œæˆ"""
        
        if topic == "family":
            return "å®¶æ—ã¨ã®æ™‚é–“ã‚’å¤§åˆ‡ã«ã—ãªãŒã‚‰ã€ä»Šå¾Œã‚‚æ—¥ã€…ã®æ°—ã¥ãã‚’çš†ã•ã‚“ã¨å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "work":
            return "ä»•äº‹ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã€ä»Šå¾Œã‚‚æ”¹å–„ã‚’é‡ã­ãªãŒã‚‰çš†ã•ã‚“ã¨çµŒé¨“ã‚’å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "lifestyle":
            return "ç”Ÿæ´»ã‚’è±Šã‹ã«ã™ã‚‹ãƒ’ãƒ³ãƒˆã‚’ã€ä»Šå¾Œã‚‚çš†ã•ã‚“ã¨å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"
        elif topic == "learning":
            return "å­¦ã³ç¶šã‘ã‚‹ã“ã¨ã®å¤§åˆ‡ã•ã‚’ã€ä»Šå¾Œã‚‚çš†ã•ã‚“ã¨å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"
        else:
            return "ä»Šå¾Œã‚‚ã“ã†ã—ãŸæ°—ã¥ãã‚’çš†ã•ã‚“ã¨å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"

    def create_fallback_article(self) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨˜äº‹"""
        return """ãƒãƒŠãƒŸã§ã™ã€‚

ä»Šå›ã¯éŸ³å£°é…ä¿¡ã®å†…å®¹ã«ã¤ã„ã¦ãŠè©±ã—ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚

æœ€è¿‘æ„Ÿã˜ã¦ã„ã‚‹ã“ã¨ã‚„æ—¥ã€…ã®æ°—ã¥ãã‚’çš†ã•ã‚“ã¨å…±æœ‰ã§ãã‚Œã°ã¨æ€ã£ã¦ã„ã¾ã™ã€‚

---------------

ä»Šå¾Œã‚‚ã“ã†ã—ãŸå†…å®¹ã‚’çš†ã•ã‚“ã¨å…±æœ‰ã—ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚"""

    def generate_perfect_article(self, transcript: str) -> str:
        """å®Œç’§ãªè¨˜äº‹ã‚’ç”Ÿæˆ"""
        
        print("ğŸ”§ æ–‡å­—èµ·ã“ã—ã‚’ä¿®æ­£ä¸­...")
        
        # 1. é«˜åº¦ãªæ–‡å­—èµ·ã“ã—ä¿®æ­£
        corrected_text = self.advanced_transcript_correction(transcript)
        
        # 2. è©±ã—è¨€è‘‰ã‚’æ›¸ãè¨€è‘‰ã«å¤‰æ›
        written_text = self.speech_to_writing_conversion(corrected_text)
        
        print("ğŸ“ æ„å‘³ã®ã‚ã‚‹å†…å®¹ã‚’æŠ½å‡ºä¸­...")
        
        # 3. æ„å‘³ã®ã‚ã‚‹å†…å®¹ã‚’æŠ½å‡º
        meaningful_sentences = self.extract_meaningful_content(written_text)
        
        # 4. ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯ã‚’ç‰¹å®š
        topic = self.identify_main_topic(meaningful_sentences)
        
        print(f"ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯: {topic}")
        
        # 5. æ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ä½œæˆ
        article = self.create_structured_article(meaningful_sentences, topic)
        
        return article

    def process_audio_file(self, audio_path: str):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆ"""
        filename = Path(audio_path).name
        
        # å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨ã‚¯ãƒªã‚¢
        self.cleanup_previous_session()
        
        print(f"\nğŸµ æ–‡å­—èµ·ã“ã—ä¸­...")
        
        # æ–‡å­—èµ·ã“ã—
        transcript = self.transcribe_with_whisper(audio_path)
        
        if not transcript:
            print("âŒ æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        print(f"ğŸ¤– è¨˜äº‹ç”Ÿæˆä¸­...")
        
        # å®Œç’§ãªè¨˜äº‹ç”Ÿæˆ
        article = self.generate_perfect_article(transcript)
        
        print(f"âœ… å‡¦ç†å®Œäº†\n")
        
        # çµæœè¡¨ç¤º
        self.display_results(article)

    def display_results(self, article: str):
        """çµæœã‚’è¡¨ç¤º"""
        # è¨˜äº‹ã‚’ç›´æ¥è¡¨ç¤º
        print("=" * 80)
        print("ğŸ“° ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹:")
        print("=" * 80)
        print(article)
        print("=" * 80)
        
        # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼
        try:
            pyperclip.copy(article)
            print("\nâœ… è¨˜äº‹ã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ä¿å­˜ã—ã¾ã—ãŸï¼")
        except Exception as e:
            print(f"âš ï¸ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ä¿å­˜ã«å¤±æ•—: {e}")

    def print_banner(self):
        """ãƒãƒŠãƒ¼è¡¨ç¤º"""
        print("ğŸ™ï¸" + "=" * 60)
        print("    å®Œç’§è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
        print("    âœ¨ éŸ³å£°ã‹ã‚‰é«˜å“è³ªnoteè¨˜äº‹ã¸ã®å®Œå…¨å¤‰æ›")
        print("=" * 62)
        print()

    def main(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        parser = argparse.ArgumentParser(description='å®Œç’§è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ')
        parser.add_argument('audio_file', nargs='?', help='éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
        parser.add_argument('--model', choices=['tiny', 'base', 'small', 'medium', 'large'], 
                          default='tiny', help='Whisperãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š')
        
        args = parser.parse_args()
        
        # ãƒ¢ãƒ‡ãƒ«æŒ‡å®šãŒã‚ã‚Œã°è¨­å®š
        if args.model:
            self.model_name = args.model
        
        self.print_banner()
        
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   1. ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦Enter")
        print("   2. ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç›´æ¥å…¥åŠ›")
        print()
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if args.audio_file:
            audio_path = args.audio_file.strip().strip('"').strip("'")
            audio_path = os.path.expanduser(audio_path)
            
            if os.path.exists(audio_path):
                self.process_audio_file(audio_path)
            else:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_path}")
            return
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
        while True:
            print("ğŸ¯ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            print("   (çµ‚äº†ã™ã‚‹ã«ã¯ 'q' ã‚’å…¥åŠ›)")
            audio_input = input("ğŸ™ï¸ ãƒ•ã‚¡ã‚¤ãƒ«: ").strip()
            
            if audio_input.lower() in ['q', 'quit', 'exit']:
                break
            
            if not audio_input:
                continue
            
            # ãƒ‘ã‚¹ã®æ•´ç†ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œï¼‰
            audio_path = audio_input.strip()
            
            # ã‚¯ã‚ªãƒ¼ãƒˆæ–‡å­—ã‚’å‰Šé™¤
            if audio_path.startswith('"') and audio_path.endswith('"'):
                audio_path = audio_path[1:-1]
            elif audio_path.startswith("'") and audio_path.endswith("'"):
                audio_path = audio_path[1:-1]
            
            # å…¨ã¦ã®ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’å‡¦ç†
            audio_path = audio_path.replace('\\ ', ' ')
            audio_path = audio_path.replace('\\~', '~')
            audio_path = audio_path.replace('\\\\', '\\')
            
            # ãƒãƒ«ãƒ€å±•é–‹
            audio_path = os.path.expanduser(audio_path)
            
            print(f"ğŸ” å‡¦ç†é–‹å§‹: {os.path.basename(audio_path)}")
            
            if os.path.exists(audio_path):
                self.process_audio_file(audio_path)
            else:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            # æ¬¡ã®å‡¦ç†ã‚’ç¢ºèª
            print("\n" + "=" * 60)
            next_action = input("ğŸ”„ åˆ¥ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower().strip()
            if next_action not in ['y', 'yes']:
                break
        
        print("ğŸ‘‹ ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼")

if __name__ == "__main__":
    generator = PerfectArticleGenerator()
    generator.main()